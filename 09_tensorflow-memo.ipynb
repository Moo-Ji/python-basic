{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_7:0\", shape=(), dtype=string)\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "#tensorflow\n",
    "#google이 만든 머신러닝을 위한 라이브러리(python, c언어)\n",
    "#tensorflow를 이용해 보자\n",
    "#hello world를 출력\n",
    "\n",
    "#tensorflow의 구성요소\n",
    "#1.node : 수학적인 연산을 담당, 데이터의 입출력 (tensor의 입출력) / 동그라미\n",
    "#2.tensor : 다차원 array(주로 matrix(2차원))\n",
    "#3. edge : 한 node가 가지고 있는 tensor를 다른 node로 이동 /선\n",
    "\n",
    "#tensorflow은 노드와 텐서와 에지로 구성되어 있는 그래프를 만드는 것, 방향성이 있는 그래프\n",
    "#runner(session) : 노드를 실행시켜주는 역할을 함\n",
    "\n",
    "import tensorflow as tf\n",
    "my_node = tf.constant(\"Hello World\")\n",
    "print(my_node)       #몇번째 상수, 현재데이터의 형태 shape, type\n",
    "#shape(3,) : 1차원 3개데이터가 들어가 있음,  shape() : 차원이 없다, 리스트가 아니다 > 하나의 값이다\n",
    "\n",
    "sess = tf.Session() #session, runner(node를 실행시켜줌)\n",
    "print(sess.run(my_node).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0, 20.0, 30.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "node1 = tf.constant(10, dtype=tf.float32)\n",
    "node2 = tf.constant(20, dtype=tf.float32)\n",
    "\n",
    "node3 = node1+node2  #tf.add(node1,node2) 정형적인 방식\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(node3) #run(실행시킬 노드를 지정해줌) = 실행\n",
    "sess.run([node1,node2,node3]) #값 세개 나오니깐 리스트로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20., 40., 60., 80.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#placeholder(데이터를 받아들이는 그릇 = 입력 파라미터)\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "node1 = tf.placeholder(dtype=tf.float32)\n",
    "node2 = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "node3 = node1+node2\n",
    "\n",
    "sess=tf.Session()\n",
    "#sess.run(node3, feed_dict={node1:100, node2:200})\n",
    "#sess.run(node3, feed_dict={node1:input(), node2:input()})\n",
    "sess.run(node3, feed_dict={node1:[10,20,30,40], node2:[10,20,30,40]})  #node1과 2 개수 맞춰줘야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_16:0' shape=(3,) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#node1=tf.constant(3, dtype=tf.float32)\n",
    "node1=tf.constant([1,2,3], dtype=tf.float32)\n",
    "node1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:[-0.07102275], b:[-1.4112241], cost:57.88896560668945\n",
      "w:[2.26859], b:[0.38943183], cost:0.053737591952085495\n",
      "w:[2.1304696], b:[0.703412], cost:0.012679941952228546\n",
      "w:[2.0633762], b:[0.8559309], cost:0.0029919345397502184\n",
      "w:[2.0307853], b:[0.9300176], cost:0.000705974642187357\n",
      "w:[2.0149543], b:[0.9660053], cost:0.0001665841118665412\n",
      "w:[2.007264], b:[0.98348725], cost:3.9304388337768614e-05\n",
      "w:[2.0035286], b:[0.9919786], cost:9.274586773244664e-06\n",
      "w:[2.0017152], b:[0.9961017], cost:2.1904731966060353e-06\n",
      "w:[2.0008342], b:[0.9981038], cost:5.182970994610514e-07\n"
     ]
    }
   ],
   "source": [
    "#간단한 linear regression을 이용한 머신러닝\n",
    "import tensorflow as tf\n",
    "\n",
    "#training data set\n",
    "#x = [1,2,3]   #독립변수, 입력데이터\n",
    "#y = [1,2,3]   #종속변수, 입력데이터의 label\n",
    "\n",
    "x = [1,2,3]   #독립변수, 입력데이터\n",
    "y = [3,5,7]   #종속변수, 입력데이터의 label\n",
    "#w=2  b=1\n",
    "\n",
    "\n",
    "#weight&bias 정의 (w와 b의 초깃값은 랜덤으로)\n",
    "W=tf.Variable(tf.random_normal([1]), name=\"weight\") #변수\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\") #변수\n",
    "\n",
    "#Hypothesis 가설 (우리가 최종적으로 알아내야 하는 직선)\n",
    "#데이터에 가장 인접한 직선, 예측모델이 만들어졋으니 prediction이 가능\n",
    "H=W*x+b\n",
    "\n",
    "#Cost function(Loss functino, 비용함수)\n",
    "#Cost function이 최소가 되는 W와 b값 구하는 것이 목적\n",
    "cost=tf.reduce_mean(tf.square(H-y))   #square 제곱\n",
    "\n",
    "#cost function의 minimize작업\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) #GD(하강)알고리즘 : 한단계 최솟값을 찾는 알고리즘\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#그래프를 실행시키기 위한 runner역할을 하는 session\n",
    "sess = tf.Session()\n",
    "\n",
    "#Variable로 사용할 경우 초기화를 시켜줘야 함\n",
    "sess.run(tf.global_variables_initializer())   \n",
    "\n",
    "for step in range(3000):\n",
    "    _,w_val,b_val,cost_val= sess.run([train,W,b,cost])   #각 노드가 가지고 있는 값을 뽑아냄 \n",
    "    if step % 300 ==0: #300번 반복될때마다 출력\n",
    "        print(\"w:{}, b:{}, cost:{}\".format(w_val,b_val,cost_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:[-0.09771606], b:[-0.06491436], cost:38.7179069519043\n",
      "w:[2.025446], b:[0.9421557], cost:0.00048231627442874014\n",
      "w:[2.01236], b:[0.9719026], cost:0.00011380054638721049\n",
      "w:[2.006004], b:[0.9863512], cost:2.685286926862318e-05\n",
      "w:[2.002917], b:[0.99336904], cost:6.337811555567896e-06\n",
      "w:[2.0014184], b:[0.9967766], cost:1.4978785429775598e-06\n",
      "w:[2.000691], b:[0.99843085], cost:3.550389067186188e-07\n",
      "w:[2.0003366], b:[0.99923563], cost:8.421839226002703e-08\n",
      "w:[2.0001638], b:[0.99962693], cost:2.0033136038932753e-08\n",
      "w:[2.0000803], b:[0.9998156], cost:4.8977804034677774e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.000303], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#간단한 linear regression을 이용한 머신러닝\n",
    "import tensorflow as tf\n",
    "\n",
    "#training data set\n",
    "x_data = [1,2,3]   #독립변수, 입력데이터\n",
    "y_data= [3,5,7]   #종속변수, 입력데이터의 label\n",
    "\n",
    "\n",
    "#placeholder\n",
    "x=tf.placeholder(dtype=tf.float32)\n",
    "y=tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "\n",
    "#weight&bias 정의 (w와 b의 초깃값은 랜덤으로)\n",
    "W=tf.Variable(tf.random_normal([1]), name=\"weight\") #변수\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\") #변수\n",
    "\n",
    "#Hypothesis 가설 (우리가 최종적으로 알아내야 하는 직선)\n",
    "#데이터에 가장 인접한 직선, 예측모델이 만들어졋으니 prediction이 가능\n",
    "H=W*x+b\n",
    "\n",
    "#Cost function(Loss functino, 비용함수)\n",
    "#Cost function이 최소가 되는 W와 b값 구하는 것이 목적\n",
    "cost=tf.reduce_mean(tf.square(H-y))   #square 제곱\n",
    "\n",
    "#cost function의 minimize작업\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) #GD(하강)알고리즘 : 한단계 최솟값을 찾는 알고리즘\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#그래프를 실행시키기 위한 runner역할을 하는 session\n",
    "sess = tf.Session()\n",
    "\n",
    "#Variable로 사용할 경우 초기화를 시켜줘야 함\n",
    "sess.run(tf.global_variables_initializer())   \n",
    "\n",
    "for step in range(3000):\n",
    "    _,w_val,b_val,cost_val= sess.run([train,W,b,cost],feed_dict={x:x_data,y:y_data})   #각 노드가 가지고 있는 값을 뽑아냄 \n",
    "    if step % 300 ==0: #300번 반복될때마다 출력\n",
    "        print(\"w:{}, b:{}, cost:{}\".format(w_val,b_val,cost_val))\n",
    "    \n",
    "\n",
    "#prediction\n",
    "sess.run(H, feed_dict={x:10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정 조건하에 검증\n",
    "#카이제곱\n",
    "#독립 t두 집단의 평균이 관련이 있느냐 \n",
    "#대응표본 t한 집단의 전과 후의 효과\n",
    "#아노바 범주가 2개이상일 경우\n",
    "\n",
    "#회귀분석\n",
    "#두개의 파라미터값이 관계가 있느냐 없느냐\n",
    "\n",
    "#선형회귀분석\n",
    "#기울기와 절편을 구하는 과정을 학습이라고 한다\n",
    "#최소제곱법활용(주로),기대값과 공분산 활용\n",
    "#차이를 제곱해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 568.1011962890625\n",
      "cost : 5.9574456214904785\n",
      "cost : 5.384549140930176\n",
      "cost : 4.969062805175781\n",
      "cost : 4.667737007141113\n",
      "cost : 4.4492058753967285\n",
      "cost : 4.290719032287598\n",
      "cost : 4.175779342651367\n",
      "cost : 4.092419147491455\n",
      "cost : 4.031965255737305\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([32.575054], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#기본적인 linear regression 예제\n",
    "import tensorflow as tf #tensor flow module을 불러들인다\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12345)\n",
    "#training data set\n",
    "x_data = np.arange(0,20,1)\n",
    "y_data = np.array([t*2 + np.random.normal(2,2) for t in x_data])   #lable에 해당\n",
    "\n",
    "#일단 먼저 눈으로 확인\n",
    "plt.scatter(x_data,y_data)\n",
    "#plt.show()\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(dtype=tf.float32)  #shape과 type이 들어감/ 빈공간\n",
    "Y=tf.placeholder(dtype=tf.float32)  #shape과 type이 들어감\n",
    "\n",
    "#Weignt & bias\n",
    "W=tf.Variable(tf.random_normal([1]), name=\"weight\")  #난수로 하나만 발생\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "H=W*X+b\n",
    "\n",
    "#cost function\n",
    "cost = tf.reduce_mean(tf.square(H-Y))   #square 제곱함수\n",
    "\n",
    "#train 학습노드\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)  #0.01넣었을때 값이 안나와서 점점 줄임\n",
    "#minimize 함수는 해당 코스트 함수를 한단계 줄인다\n",
    "\n",
    "#session 해당 그래프를 실행시킬 수 있는/ variable에 대한 초기화 진행\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())  #초기화\n",
    "\n",
    "#학습   #트레이닝 데이타 전체 이용해서 한번 학습시키는 것 = 1에폭\n",
    "for step in range(3000):  #3000에폭  #데이터 사이즈가 작기때문에 여러번 돌리는게 가능\n",
    "    _,cost_val=  sess.run([train,cost], feed_dict={X:x_data,Y:y_data})   #train노드는 받을 결과값이 없다= _\n",
    "    if step%300==0:\n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "        \n",
    "#입력데이터에 대한 처리가 이루어져야 정상적으로 학습이 진행될 수 있다.\n",
    "#만약 학습이 정상적으로 이루어졌으면 w,b값이 결정\n",
    "\n",
    "x_line=np.arange(0,20,1)\n",
    "y_line=np.array([sess.run(W)*t+sess.run(b) for t in x_line])  \n",
    "plt.plot(x_line,y_line,\"r\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#prediction\n",
    "sess.run(H, feed_dict={X:15})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0   41.0    190.0   7.4    67      5    1\n",
       "1   36.0    118.0   8.0    72      5    2\n",
       "2   12.0    149.0  12.6    74      5    3\n",
       "3   18.0    313.0  11.5    62      5    4\n",
       "4    NaN      NaN  14.3    56      5    5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ozone데이터를 이용한 linear regression\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1.Data Loading\n",
    "data=pd.read_csv(\"./data/ozone.csv\", sep=\",\")\n",
    "data.head()\n",
    "\n",
    "#temp와 ozone의 관계를 알아보기위해 plt를 이용해서 그림을 그려라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 1.3779722452163696\n",
      "cost : 1.0887963771820068\n",
      "cost : 0.895678699016571\n",
      "cost : 0.766710638999939\n",
      "cost : 0.6805828809738159\n",
      "cost : 0.6230648159980774\n",
      "cost : 0.5846529006958008\n",
      "cost : 0.5590004324913025\n",
      "cost : 0.5418691039085388\n",
      "cost : 0.530428409576416\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([10.035938], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ozone데이터를 이용한 linear regression\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1.Data Loading\n",
    "data=pd.read_csv(\"./data/ozone.csv\", sep=\",\")\n",
    "\n",
    "#Data에 nan결측값이 있으면 제거하거나 다른 값으로 대체해서 사용\n",
    "df=data.dropna(how=\"any\", inplace=False) \n",
    "\n",
    "##데이터 분포를 보려면 scatter를 이용\n",
    "x_data=np.array((df[\"Temp\"]-df[\"Temp\"].mean())/df[\"Temp\"].std())\n",
    "y_data=np.array((df[\"Ozone\"]-df[\"Ozone\"].mean())/df[\"Ozone\"].std())\n",
    "\n",
    "plt.scatter(x_data,y_data, marker=\"P\") #앞에는 독립변수x, 뒤에는 y\n",
    "#plt.show()\n",
    "\n",
    "#데이터의 단위가 서로 다르기에 해당 데이터를 같은 형식으로 바꿔줌\n",
    "#Normalization, Standardization\n",
    "#Standardization : (현재값 - 평균) / 표준편차   =일정하게 표준화 시켜줌\n",
    "#Normalization : (현재값 - 최솟값) / (최댓값 - 최솟값)   \n",
    "\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(dtype=tf.float32)  #shape과 type이 들어감/ 빈공간\n",
    "Y=tf.placeholder(dtype=tf.float32)  #shape과 type이 들어감\n",
    "\n",
    "#Weignt & bias\n",
    "W=tf.Variable(tf.random_normal([1]), name=\"weight\")  #난수로 하나만 발생\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "H=W*X+b\n",
    "\n",
    "#cost function\n",
    "cost = tf.reduce_mean(tf.square(H-Y))   #square 제곱함수\n",
    "\n",
    "#train 학습노드\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)  #0.01넣었을때 값이 안나와서 점점 줄임\n",
    "#minimize 함수는 해당 코스트 함수를 한단계 줄인다\n",
    "\n",
    "#session 해당 그래프를 실행시킬 수 있는/ variable에 대한 초기화 진행\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())  #초기화\n",
    "\n",
    "#학습   #트레이닝 데이타 전체 이용해서 한번 학습시키는 것 = 1에폭\n",
    "for step in range(100):  #3000에폭  #데이터 사이즈가 작기때문에 여러번 돌리는게 가능\n",
    "    _,cost_val= sess.run([train,cost], feed_dict={X:x_data,Y:y_data})   #train노드는 받을 결과값이 없다= _\n",
    "    if step%10==0:\n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "        \n",
    "#입력데이터에 대한 처리가 이루어져야 정상적으로 학습이 진행될 수 있다.\n",
    "#만약 학습이 정상적으로 이루어졌으면 w,b값이 결정\n",
    "\n",
    "x_line=np.array((x_data-x_data.mean())/x_data.std())\n",
    "#y_line=(y_data-y_data.mean())/y_data.std()\n",
    "y_line=np.array([sess.run(W)*t+sess.run(b) for t in x_line])  \n",
    "plt.plot(x_line,y_line,\"r\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#prediction\n",
    "sess.run(H, feed_dict={X:15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "#Data Loading\n",
    "data=pd.read_csv(\"./data/ozone.csv\", sep=\",\")\n",
    "df=data.dropna(how=\"any\", inplace=False)\n",
    "\n",
    "#독립변수와 종속변수를 뽑는다\n",
    "x=df[\"Temp\"]     #입력파라미터(x)=레이블df[\"Temp\"]\n",
    "y=df[\"Ozone\"]    #입력파리미터(y)=레이블\n",
    "\n",
    "result=stats.linregress(x,y)\n",
    "result   #slope 기울기 / intercept 절편 / rvalue 상관계수(0에 가까우면 상관없음) /\n",
    "         \n",
    "W=result[0]\n",
    "b=result[1]\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,W*x+b,\"r\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple linear regression\n",
    "import tensorflow as tf\n",
    "\n",
    "#training data set\n",
    "x_data=[[73,80,75],\n",
    "        [93,88,93],\n",
    "        [89,91,90],\n",
    "        [96,98,100],\n",
    "        [73,66,70]]\n",
    "\n",
    "y_data=[[152],[185],[180],[196],[142]]  #값이 하나지만 2차원형태의 matrix로 표현\n",
    "\n",
    "#placeholder   #사용할 데이터에 따라 플레이스홀더의 shape을 지정해준다\n",
    "x=tf.placeholder(shape=[None,3], dtype=tf.float32) #shape=[행,열] 데이터 행렬을 n행 n열로 받아들인다\n",
    "y=tf.placeholder(shape=[None,1], dtype=tf.float32) #None이란 행의 개수는 상관 없음\n",
    "\n",
    "#weight, bias\n",
    "W=tf.Variable(tf.random_normal([3,1]), name=\"weight\")  #3행 1열로 행열 곱이기 때문에 shape을 맞춰줌\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "#원래는 H=W*t+b\n",
    "#but 행렬곱이기 때문에\n",
    "H=tf.matmul(x,W)+b\n",
    "\n",
    "#그 다음부터는 동일과정 진행\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0   41.0    190.0   7.4    67      5    1\n",
       "1   36.0    118.0   8.0    72      5    2\n",
       "2   12.0    149.0  12.6    74      5    3\n",
       "3   18.0    313.0  11.5    62      5    4\n",
       "4    NaN      NaN  14.3    56      5    5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ozone데이터를 이용한 multi regression\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1.Data Loading\n",
    "data=pd.read_csv(\"./data/ozone.csv\", sep=\",\")\n",
    "data.head()\n",
    "\n",
    "\n",
    "#temp,solar.R,wind와 ozone의 관계를 알아보기위해 plt를 이용해서 그림을 그려라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\data_env\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Anaconda3\\envs\\data_env\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Anaconda3\\envs\\data_env\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\envs\\data_env\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 4.843505859375\n",
      "cost : 0.9183672070503235\n",
      "cost : 0.4679344892501831\n",
      "cost : 0.4023086726665497\n",
      "cost : 0.39235129952430725\n",
      "cost : 0.3908297121524811\n",
      "cost : 0.39059698581695557\n",
      "cost : 0.3905613422393799\n",
      "cost : 0.39055588841438293\n",
      "cost : 0.3905550241470337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[60.196682]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1.Data Loading\n",
    "data=pd.read_csv(\"./data/ozone.csv\", sep=\",\")\n",
    "\n",
    "#Data에 nan결측값이 있으면 제거하거나 다른 값으로 대체해서 사용\n",
    "df=data.dropna(how=\"any\", inplace=False) \n",
    "\n",
    "df[\"Temp_Stan\"] = (df[\"Temp\"]-df[\"Temp\"].mean())/df[\"Temp\"].std()\n",
    "df[\"Wind_Stan\"] = (df[\"Wind\"]-df[\"Wind\"].mean())/df[\"Wind\"].std()\n",
    "df[\"Solar.R_Stan\"] = (df[\"Solar.R\"]-df[\"Solar.R\"].mean())/df[\"Solar.R\"].std()\n",
    "df[\"Ozone_Stan\"] = (df[\"Ozone\"]-df[\"Ozone\"].mean())/df[\"Ozone\"].std()\n",
    "#display(df)\n",
    "\n",
    "x_data = df[[\"Temp_Stan\",\"Wind_Stan\",\"Solar.R_Stan\"]].values\n",
    "#display(x_data)\n",
    "y_data = df[\"Ozone_Stan\"].values.reshape(-1,1)\n",
    "#display(y_data)\n",
    "\n",
    "#placeholder   #사용할 데이터에 따라 플레이스홀더의 shape을 지정해준다\n",
    "x=tf.placeholder(shape=[None,3], dtype=tf.float32) #shape=[행,열] 데이터 행렬을 n행 n열로 받아들인다\n",
    "y=tf.placeholder(shape=[None,1], dtype=tf.float32) #None이란 행의 개수는 상관 없음\n",
    "\n",
    "#weight, bias\n",
    "W=tf.Variable(tf.random_normal([3,1]), name=\"weight\")  #3행 1열로 행열 곱이기 때문에 shape을 맞춰줌\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "#원래는 H=W*t+b\n",
    "#but 행렬곱이기 때문에\n",
    "H=tf.matmul(x,W)+b\n",
    "\n",
    "#cost function\n",
    "cost = tf.reduce_mean(tf.square(H-y))   #square 제곱함수\n",
    "\n",
    "#train 학습노드\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)  #0.01넣었을때 값이 안나와서 점점 줄임\n",
    "#minimize 함수는 해당 코스트 함수를 한단계 줄인다\n",
    "\n",
    "#session 해당 그래프를 실행시킬 수 있는/ variable에 대한 초기화 진행\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())  #초기화\n",
    "\n",
    "#학습   #트레이닝 데이타 전체 이용해서 한번 학습시키는 것 = 1에폭\n",
    "for step in range(1000):  \n",
    "    _,cost_val= sess.run([train,cost], feed_dict={x:x_data,y:y_data})   #train노드는 받을 결과값이 없다= _\n",
    "    if step%100==0:\n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "        \n",
    "\n",
    "#prediction   : 데이터가 맞는지 확인, \n",
    "sess.run(H, feed_dict={x:[[67,7.4,190.0]]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0   41.0    190.0   7.4    67      5    1\n",
       "1   36.0    118.0   8.0    72      5    2\n",
       "2   12.0    149.0  12.6    74      5    3\n",
       "3   18.0    313.0  11.5    62      5    4\n",
       "6   23.0    299.0   8.6    65      5    7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.55963303, 0.27717391, 0.25      ],\n",
       "       [0.33944954, 0.30978261, 0.375     ],\n",
       "       [0.43425076, 0.55978261, 0.425     ],\n",
       "       [0.93577982, 0.5       , 0.125     ],\n",
       "       [0.89296636, 0.3423913 , 0.2       ],\n",
       "       [0.28134557, 0.625     , 0.05      ],\n",
       "       [0.03669725, 0.9673913 , 0.1       ],\n",
       "       [0.76146789, 0.40217391, 0.3       ],\n",
       "       [0.86544343, 0.375     , 0.225     ],\n",
       "       [0.81651376, 0.4673913 , 0.275     ],\n",
       "       [0.17737003, 0.5923913 , 0.025     ],\n",
       "       [1.        , 0.5       , 0.175     ],\n",
       "       [0.91743119, 0.52717391, 0.225     ],\n",
       "       [0.21712538, 0.875     , 0.        ],\n",
       "       [0.96330275, 0.5       , 0.275     ],\n",
       "       [0.11314985, 0.40217391, 0.125     ],\n",
       "       [0.0030581 , 0.40217391, 0.05      ],\n",
       "       [0.95718654, 0.77717391, 0.4       ],\n",
       "       [0.05504587, 0.40217391, 0.1       ],\n",
       "       [0.25993884, 0.52717391, 0.1       ],\n",
       "       [0.01834862, 0.52717391, 0.25      ],\n",
       "       [0.74923547, 0.68478261, 0.6       ],\n",
       "       [0.66055046, 0.18478261, 0.55      ],\n",
       "       [0.83180428, 0.27717391, 0.475     ],\n",
       "       [0.36697248, 0.40217391, 0.625     ],\n",
       "       [0.86850153, 0.625     , 0.825     ],\n",
       "       [0.96636086, 0.5       , 0.75      ],\n",
       "       [0.43119266, 0.30978261, 0.625     ],\n",
       "       [0.56269113, 0.68478261, 0.5       ],\n",
       "       [0.8470948 , 1.        , 0.375     ],\n",
       "       [0.09174312, 0.375     , 0.2       ],\n",
       "       [0.34556575, 0.5       , 0.4       ],\n",
       "       [0.39755352, 0.43478261, 0.475     ],\n",
       "       [0.80122324, 0.09782609, 0.675     ],\n",
       "       [0.73700306, 0.375     , 0.7       ],\n",
       "       [0.70030581, 0.375     , 0.6       ],\n",
       "       [0.51376147, 0.125     , 0.65      ],\n",
       "       [0.93883792, 0.4673913 , 0.65      ],\n",
       "       [0.82262997, 0.15217391, 0.775     ],\n",
       "       [0.79510703, 0.2173913 , 0.875     ],\n",
       "       [0.81039755, 0.18478261, 0.875     ],\n",
       "       [0.51376147, 0.27717391, 0.8       ],\n",
       "       [0.78593272, 0.65217391, 0.4       ],\n",
       "       [0.51376147, 0.68478261, 0.6       ],\n",
       "       [0.12538226, 0.65217391, 0.575     ],\n",
       "       [0.77370031, 0.25      , 0.6       ],\n",
       "       [0.81651376, 0.43478261, 0.625     ],\n",
       "       [0.85015291, 0.2173913 , 0.675     ],\n",
       "       [0.55045872, 0.15217391, 0.75      ],\n",
       "       [0.65137615, 0.5       , 0.7       ],\n",
       "       [0.        , 0.25      , 0.425     ],\n",
       "       [0.87767584, 0.3423913 , 0.725     ],\n",
       "       [0.66055046, 0.30978261, 0.7       ],\n",
       "       [0.22629969, 0.3423913 , 0.625     ],\n",
       "       [0.2293578 , 0.52717391, 0.725     ],\n",
       "       [0.62996942, 0.27717391, 0.775     ],\n",
       "       [0.81957187, 0.27717391, 0.725     ],\n",
       "       [0.75229358, 0.27717391, 0.65      ],\n",
       "       [0.75535168, 0.375     , 0.6       ],\n",
       "       [0.2324159 , 0.25      , 0.6       ],\n",
       "       [0.05198777, 0.625     , 0.6       ],\n",
       "       [0.21406728, 0.27717391, 0.625     ],\n",
       "       [0.75840979, 0.0923913 , 0.8       ],\n",
       "       [0.67889908, 0.43478261, 0.825     ],\n",
       "       [0.6116208 , 0.30978261, 0.825     ],\n",
       "       [0.56574924, 0.5       , 0.725     ],\n",
       "       [0.81345566, 0.5       , 0.625     ],\n",
       "       [0.4587156 , 0.40217391, 0.575     ],\n",
       "       [0.19571865, 0.43478261, 0.5       ],\n",
       "       [0.13455657, 0.2173913 , 0.55      ],\n",
       "       [0.33027523, 0.27717391, 0.475     ],\n",
       "       [0.72477064, 0.4673913 , 0.525     ],\n",
       "       [0.55963303, 0.43478261, 0.525     ],\n",
       "       [0.7706422 , 0.7173913 , 0.5       ],\n",
       "       [0.08868502, 0.65217391, 0.375     ],\n",
       "       [0.62691131, 0.40217391, 0.55      ],\n",
       "       [0.70642202, 0.05978261, 0.6       ],\n",
       "       [0.63608563, 0.30978261, 0.725     ],\n",
       "       [0.59938838, 0.40217391, 1.        ],\n",
       "       [0.66666667, 0.        , 0.925     ],\n",
       "       [0.70336391, 0.2173913 , 0.975     ],\n",
       "       [0.55351682, 0.2173913 , 0.925     ],\n",
       "       [0.48929664, 0.25      , 0.85      ],\n",
       "       [0.58103976, 0.15217391, 0.875     ],\n",
       "       [0.5382263 , 0.02717391, 0.9       ],\n",
       "       [0.55657492, 0.125     , 0.9       ],\n",
       "       [0.26911315, 0.27717391, 0.75      ],\n",
       "       [0.25993884, 0.7173913 , 0.675     ],\n",
       "       [0.74923547, 0.4673913 , 0.575     ],\n",
       "       [0.65137615, 0.43478261, 0.525     ],\n",
       "       [0.68195719, 0.4673913 , 0.45      ],\n",
       "       [0.7706422 , 0.40217391, 0.4       ],\n",
       "       [0.70030581, 0.68478261, 0.6       ],\n",
       "       [0.7706422 , 0.7173913 , 0.475     ],\n",
       "       [0.70642202, 0.2173913 , 0.5       ],\n",
       "       [0.05198777, 0.4673913 , 0.35      ],\n",
       "       [0.32110092, 0.5       , 0.35      ],\n",
       "       [0.70336391, 0.25      , 0.525     ],\n",
       "       [0.66360856, 0.625     , 0.25      ],\n",
       "       [0.06116208, 0.43478261, 0.475     ],\n",
       "       [0.70642202, 0.43478261, 0.275     ],\n",
       "       [0.59327217, 0.30978261, 0.625     ],\n",
       "       [0.70642202, 0.55978261, 0.175     ],\n",
       "       [0.02140673, 0.375     , 0.35      ],\n",
       "       [0.40366972, 0.43478261, 0.6       ],\n",
       "       [0.12844037, 0.43478261, 0.3       ],\n",
       "       [0.03975535, 0.77717391, 0.15      ],\n",
       "       [0.56880734, 0.25      , 0.325     ],\n",
       "       [0.56269113, 0.65217391, 0.45      ],\n",
       "       [0.37920489, 0.30978261, 0.475     ],\n",
       "       [0.66055046, 0.5       , 0.275     ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#1.Data Loading\n",
    "data=pd.read_csv(\"./data/ozone.csv\", sep=\",\")\n",
    "\n",
    "#Data에 nan결측값이 있으면 제거하거나 다른 값으로 대체해서 사용\n",
    "df=data.dropna(how=\"any\", inplace=False)  #111행\n",
    "display(df.head())\n",
    "\n",
    "#2.training data set\n",
    "##데이터 분포를 보려면 scatter를 이용\n",
    "x_data=MinMaxScaler().fit_transform(\n",
    "    df[[\"Solar.R\",\"Wind\",\"Temp\"]].values)\n",
    "\n",
    "y_data=MinMaxScaler().fit_transform(\n",
    "    df[[\"Ozone\",]].values.reshape(-1,1))\n",
    "\n",
    "x_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.4703\n",
      "0.049775276\n",
      "0.04371076\n",
      "0.04354223\n",
      "0.04353755\n",
      "0.043537416\n",
      "0.04353742\n",
      "0.043537416\n",
      "0.04353742\n",
      "0.04353742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.973681], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Logistic regression을 simple linear regression으로 표현 (=0과 1값으로 나오는 데이터를 simple linear regression으로 처리)\n",
    "#linear regression으로는 표현할 수 없다\n",
    "#simple linear regression  입력 파라미터 한개  \n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#traning data set\n",
    "x_data = [1,2,5,8,10]\n",
    "y_data = [0,0,0,1,1]\n",
    "\n",
    "#placeholder\n",
    "X = tf.placeholder(dtype=tf.float32)\n",
    "Y = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#Weight & bias\n",
    "W = tf.Variable(tf.random_normal([1]),name=\"weight\")  #0값은 오류 발생, w의 초기값은 난수 1개를 발생시켜서 만듬\n",
    "b = tf.Variable(tf.random_normal([1]),name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "H = W*X+b\n",
    "\n",
    "#Cost(Loss) function (비용함수)   : 최소 제곱법 가설과 입력값 y의 차이의 제곱을 가지고 평균을 내는 것\n",
    "#cost함수가 최소가 되는 w와 b값을 찾는다\n",
    "cost = tf.reduce_mean(tf.square(H-Y))    \n",
    "\n",
    "\n",
    "#train node를 생성\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)   #계속 한단계씩 줄임/ learning_rate :w값을 얼마나 줄일지 조정\n",
    "\n",
    "\n",
    "#session & 초기화          \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "#데이터를 잘 표현할 수 있는 기울기와 절편 구하기 (학습과정)\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data,Y:y_data})\n",
    "    if step % 300 == 0:   #cost값이 얼마인지 보기위해 작성\n",
    "        print(cost_val)\n",
    "        \n",
    "plt.scatter(x_data,y_data)\n",
    "plt.plot(x_data, sess.run(W)*x_data+sess.run(b), \"r\")\n",
    "plt.show\n",
    "\n",
    "x= (0.5 - sess.run(b))/sess.run(W)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#가설(H)이 바뀌면 cost도 바꿔줘야 함(logistic에서는 linear에서 사용했던 방식 사용할 수 없음)\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn  #Sample Data를 가져오기 위한  utility module #샘플데이터를 사용하는 용도(굳이 사용안해도 내가 랜덤으로 만들어 사용할 수 있음)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings #warning메서지 제어\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\") #warning을 표시하지 않음\n",
    "x,y=mglearn.datasets.make_forge()   #의미없는 데이터를 데이터셋으로 만들어줌\n",
    "#x는 2차배열로 입력 파라미터 2개 / y는 0과1로 표현되는 1차원 배열\n",
    "#x : x parameter(2개)\n",
    "#y : lable(0 or 1)\n",
    "\n",
    "mglearn.discrete_scatter(x[:,0],x[:,1],y)   #(x좌표, y좌표, 0이냐 1이냐), \n",
    "model=LogisticRegression()  #모델만들기\n",
    "clf=model.fit(x,y) #학습진행 = for문 학습 과정\n",
    "\n",
    "mglearn.plots.plot_2d_separator(clf,x,fill=False, eps=0.5) \n",
    "\n",
    "#logistic regression = 데이터영역을 구분해주는 선을 찾는게 목적, 어떻게하면 두개의 데이터를 잘 분리시켜줄까\n",
    "#but, tensorflow방식을 주로 이용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2730477\n",
      "0.48237714\n",
      "0.42641994\n",
      "0.38912827\n",
      "0.36185488\n",
      "0.34057602\n",
      "0.32336357\n",
      "0.30911133\n",
      "0.29709342\n",
      "0.28680155\n",
      "정확도 0.85714287\n",
      "예측값 [[0.]]\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow를 이용한 logistic regression\n",
    "#DataLoading\n",
    "#파일이나 network를 통해 데이터를 로딩한 후 전처리 과정\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn  #Sample Data를 가져오기 위한  utility module #샘플데이터를 사용하는 용도(굳이 사용안해도 내가 랜덤으로 만들어 사용할 수 있음)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings #warning메서지 제어\n",
    "\n",
    "#traning data set (2차원 matrix로 표현)\n",
    "x_data=[[10,0],\n",
    "      [8,1],\n",
    "      [3,3],\n",
    "      [2,3],\n",
    "      [5,1],\n",
    "      [2,0],\n",
    "      [1,0]]\n",
    "y_data=[[1],[1],[1],[1],[0],[0],[0]] \n",
    "\n",
    "#placeholder(x_data, y_data 받음)\n",
    "X=tf.placeholder(shape=[None,2],dtype=tf.float32) #x_data의 형태와 shape 맞춰줌\n",
    "Y=tf.placeholder(shape=[None,1],dtype=tf.float32) #y_data의 형태와 shape 맞춰줌\n",
    "\n",
    "#weight와 bias 지정\n",
    "W=tf.Variable(tf.random_normal([2,1]), name=\"weight\")  #변수로 지정(x의 열값,y의 열값)\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#hypothesis\n",
    "logit=tf.matmul(X,W)+b  #XW+b=Y linear regression의 hypothesis\n",
    "H=tf.sigmoid(logit)\n",
    "\n",
    "#Cost Funtion\n",
    "#cost=-tf.reduce_mean(Y*tf.log(H)+(1-Y)*tf.log(1-H))\n",
    "#위에 식을 간단하게 구하는 함수\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=Y)) \n",
    "\n",
    "#train node를 생성\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)   #계속 한단계씩 줄임/ learning_rate :w값을 얼마나 줄일지 조정\n",
    "\n",
    "\n",
    "#session & 초기화          \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습\n",
    "for step in range(3000):\n",
    "    _, cost_val=sess.run([train,cost],feed_dict={X:x_data,Y:y_data})\n",
    "    if step % 300 ==0:\n",
    "        print(cost_val)\n",
    "        \n",
    "#우리가 만든 모델이 얼마나 정확한지를 측정\n",
    "predict=tf.cast(H>0.5, dtype=tf.float32)   #cast는 타입변환함수\n",
    "correct=tf.equal(predict, Y)  #실제 데이터와 예측값 비교해서 같으면 True 다르면 False\n",
    "accuracy=tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도\",sess.run(accuracy, feed_dict={X:x_data,Y:y_data}))\n",
    "\n",
    "#prediction\n",
    "print(\"예측값\",sess.run(predict, feed_dict={X:[[3,1]]}))   #1=합격  0=불합격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression(Binary Classification)\n",
    "\n",
    "#실습예제1 : titanic\n",
    "#실습예제2 : admission = 주어진 데이터의 70%를 사용 나머지 30%를 test용으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3189149\n",
      "0.51538926\n",
      "0.48266202\n",
      "0.47277537\n",
      "0.46863934\n",
      "0.46645114\n",
      "0.46504468\n",
      "0.46399298\n",
      "0.46312332\n",
      "0.4623604\n",
      "정확도 0.7890011\n"
     ]
    }
   ],
   "source": [
    "#Titanic 분석(Tensorflow)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#data loading \n",
    "data=pd.read_csv(\"./data/titanic_data.csv\", sep=\",\")  #sep=\",\" default값\n",
    "data_x = data[[\"Sex\",\"Age\",\"Pclass\",\"Fare\"]]  #sex는 값들이 문자, pclass는 낮은 숫자가 가중치가 높음 => 바꿔줘야 함\n",
    "data_y = data[\"Survived\"]\n",
    "display(data.head())\n",
    "\n",
    "Pclass_dummies = pd.get_dummies(data_x[\"Pclass\"],prefix=\"Pclass\") #특정컬럼에 대해 더미 컬럼을 얻을 수 있음\n",
    "data_x=data_x.join(Pclass_dummies)\n",
    "data_x.drop(\"Pclass\", axis=1, inplace=True)   #inplace=True 원본을 지워라, axis=1열방향\n",
    "\n",
    "Sex_dummies=pd.get_dummies(data_x[\"Sex\"], prefix=\"Sex\")\n",
    "data_x=data_x.join(Sex_dummies)\n",
    "data_x.drop(\"Sex\", axis=1, inplace=True)   #inplace=True 원본을 지워라, axis=1열방향\n",
    "\n",
    "#training data set\n",
    "x_data = MinMaxScaler().fit_transform(data_x.values)   #작은것에서 큰것빼서 ,정규화\n",
    "y_data = data_y.values.reshape(-1,1)  #2차원 형태로 만들어줌\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,7], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "#weight & bias\n",
    "W=tf.Variable(tf.random_normal([7,1]), name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "logit=tf.matmul(X,W)+b\n",
    "H=tf.sigmoid(logit)\n",
    "\n",
    "#cost function\n",
    "cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=Y))\n",
    "\n",
    "#train\n",
    "train=tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#session, 초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습과정\n",
    "for step in range(10000):\n",
    "    _, cost_val=sess.run([train,cost], feed_dict={X:x_data,Y:y_data})\n",
    "    if step % 1000 ==0:\n",
    "        print(cost_val)\n",
    "        \n",
    "#accuracy 측정\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)  #같으면 예측이 잘된것\n",
    "accuracy=tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도\",sess.run(accuracy, feed_dict={X:x_data,Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Admission\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#data loading \n",
    "data=pd.read_csv(\"./data/admission.csv\", sep=\",\")  #sep=\",\" default값\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.75862069, 0.96551724, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.24137931, 0.58045977, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.75862069, 0.68390805, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.51724138, 0.48275862, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.37931034, 0.64942529, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.65517241, 0.60344828, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.55172414, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.75862069, 0.82758621, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.51149425, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.34482759, 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.68965517, 0.68390805, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.29885057, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.79310345, 0.82758621, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.98275862, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.44827586, 0.16666667, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.51724138, 0.56896552, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.5862069 , 0.51724138, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.4137931 , 0.46551724, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55172414, 0.71264368, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.86206897, 0.65517241, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.72413793, 0.59770115, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.75862069, 0.77011494, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.31034483, 0.51149425, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.79310345, 0.98850575, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.32758621, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.62068966, 0.68965517, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.55172414, 0.52298851, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.62068966, 0.7183908 , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55172414, 0.5       , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.37931034, 0.4137931 , 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.5862069 , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.75862069, 0.81034483, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.75862069, 0.86781609, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.51724138, 0.79885057, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.55172414, 0.68965517, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.13793103, 0.33333333, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.20689655, 0.42528736, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.96551724, 0.78735632, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.44827586, 0.83333333, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.55172414, 0.5862069 , 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.4137931 , 0.50574713, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.4137931 , 0.75862069, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.48275862, 0.43103448, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.34482759, 0.24712644, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.51724138, 0.25287356, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.79310345, 0.94252874, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.79310345, 0.60344828, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5862069 , 0.70114943, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.62068966, 0.62068966, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.48275862, 0.38505747, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.89655172, 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.75862069, 0.76436782, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.34482759, 0.40229885, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5862069 , 0.67241379, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.4137931 , 0.79310345, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.68965517, 0.83333333, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.51724138, 0.51149425, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.68965517, 0.47701149, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.55172414, 0.54022989, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.75862069, 0.6954023 , 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.48275862, 0.55747126, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.5862069 , 0.22413793, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.48275862, 0.97126437, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.62068966, 0.45977011, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.51724138, 0.62643678, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.48275862, 0.44252874, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.65517241, 0.62643678, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.62068966, 0.88505747, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.31034483, 0.63218391, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.68965517, 0.33908046, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.96551724, 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.68965517, 0.67241379, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.62068966, 0.49425287, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.82758621, 0.72413793, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55172414, 0.87356322, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.93103448, 0.31609195, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.82758621, 0.58045977, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.86206897, 0.60344828, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5862069 , 0.82183908, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.86206897, 0.96551724, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.51724138, 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55172414, 0.70689655, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.79310345, 0.50574713, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.4137931 , 0.67816092, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5862069 , 0.63218391, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.44827586, 0.29885057, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.4137931 , 0.38505747, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.68965517, 0.78735632, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.62068966, 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.93678161, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55172414, 0.86781609, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.79310345, 0.86206897, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.79310345, 0.09195402, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.68965517, 0.63793103, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5862069 , 0.87356322, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5862069 , 0.70689655, 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.68965517, 0.78735632, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.72413793, 0.49425287, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.55172414, 0.25287356, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.82758621, 0.79885057, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55172414, 0.70689655, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55172414, 0.7183908 , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.75862069, 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.44827586, 0.20689655, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.34482759, 0.43678161, 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.89655172, 0.91954023, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.62068966, 0.63218391, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.72413793, 0.52298851, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.72413793, 0.7183908 , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.45402299, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.75862069, 0.93103448, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.65517241, 0.64367816, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.68965517, 0.85632184, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.4137931 , 0.99425287, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.68965517, 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5862069 , 0.44827586, 0.        , 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.4137931 , 0.21264368, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.82758621, 0.79885057, 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.65517241, 0.93678161, 0.        , 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Admission\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#data loading \n",
    "data=pd.read_csv(\"./data/admission.csv\", sep=\",\")  #sep=\",\" default값\n",
    "data_x = data[[\"gre\",\"gpa\",\"rank\"]]  #sex는 값들이 문자, pclass는 낮은 숫자가 가중치가 높음 => 바꿔줘야 함\n",
    "data_y = data[\"admit\"]\n",
    "display(data.head())\n",
    "\n",
    "rank_dummies = pd.get_dummies(data_x[\"rank\"],prefix=\"rank\") #특정컬럼에 대해 더미 컬럼을 얻을 수 있음\n",
    "data_x=data_x.join(rank_dummies)\n",
    "data_x.drop(\"rank\", axis=1, inplace=True)   #inplace=True 원본을 지워라, axis=1열방향\n",
    "\n",
    "\n",
    "#training data set\n",
    "x_data = MinMaxScaler().fit_transform(data_x.values)   #작은것에서 큰것빼서 ,정규화\n",
    "y_data = data_y.values.reshape(-1,1)  #2차원 형태로 만들어줌\n",
    "\n",
    "x_data[280:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93280315\n",
      "0.599685\n",
      "0.5769394\n",
      "0.56594646\n",
      "0.560286\n",
      "0.5571434\n",
      "0.55524355\n",
      "0.5539897\n",
      "0.5530923\n",
      "0.55240566\n",
      "정확도 0.68333334\n"
     ]
    }
   ],
   "source": [
    "#Admission\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#data loading \n",
    "data=pd.read_csv(\"./data/admission.csv\", sep=\",\")  #sep=\",\" default값\n",
    "data_x = data[[\"gre\",\"gpa\",\"rank\"]]  #sex는 값들이 문자, pclass는 낮은 숫자가 가중치가 높음 => 바꿔줘야 함\n",
    "data_y = data[\"admit\"]\n",
    "display(data.head())\n",
    "\n",
    "rank_dummies = pd.get_dummies(data_x[\"rank\"],prefix=\"rank\") #특정컬럼에 대해 더미 컬럼을 얻을 수 있음\n",
    "data_x=data_x.join(rank_dummies)\n",
    "data_x.drop(\"rank\", axis=1, inplace=True)   #inplace=True 원본을 지워라, axis=1열방향\n",
    "\n",
    "\n",
    "#training data set\n",
    "x_data = MinMaxScaler().fit_transform(data_x.values)   #작은것에서 큰것빼서 ,정규화\n",
    "y_data = data_y.values.reshape(-1,1)  #2차원 형태로 만들어줌\n",
    "\n",
    "x_data_1=x_data[:280]\n",
    "x_data_2=x_data[280:]\n",
    "\n",
    "y_data_1=y_data[:280]\n",
    "y_data_2=y_data[280:]\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,6], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "#weight & bias\n",
    "W=tf.Variable(tf.random_normal([6,1]), name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "logit=tf.matmul(X,W)+b\n",
    "H=tf.sigmoid(logit)\n",
    "\n",
    "#cost function\n",
    "cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=Y))\n",
    "\n",
    "#train\n",
    "train=tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#session, 초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습과정\n",
    "for step in range(10000):\n",
    "    _, cost_val=sess.run([train,cost], feed_dict={X:x_data_1,Y:y_data_1})\n",
    "    if step % 1000 ==0:\n",
    "        print(cost_val)\n",
    "        \n",
    "#accuracy 측정\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)  #같으면 예측이 잘된것\n",
    "accuracy=tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도\",sess.run(accuracy, feed_dict={X:x_data_2,Y:y_data_2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0.172627\n",
       "1      0.292175\n",
       "2      0.738408\n",
       "3      0.178385\n",
       "4      0.118354\n",
       "5      0.369970\n",
       "6      0.419246\n",
       "7      0.217003\n",
       "8      0.200735\n",
       "9      0.517868\n",
       "10     0.374314\n",
       "11     0.400200\n",
       "12     0.720539\n",
       "13     0.353455\n",
       "14     0.692380\n",
       "15     0.185825\n",
       "16     0.339939\n",
       "17     0.078953\n",
       "18     0.540228\n",
       "19     0.573512\n",
       "20     0.161221\n",
       "21     0.437271\n",
       "22     0.128375\n",
       "23     0.192049\n",
       "24     0.437594\n",
       "25     0.682295\n",
       "26     0.578481\n",
       "27     0.204754\n",
       "28     0.423073\n",
       "29     0.458299\n",
       "         ...   \n",
       "370    0.398574\n",
       "371    0.317087\n",
       "372    0.376508\n",
       "373    0.530854\n",
       "374    0.411424\n",
       "375    0.187357\n",
       "376    0.415124\n",
       "377    0.589590\n",
       "378    0.202240\n",
       "379    0.218961\n",
       "380    0.463667\n",
       "381    0.346029\n",
       "382    0.349677\n",
       "383    0.672759\n",
       "384    0.186651\n",
       "385    0.351893\n",
       "386    0.528429\n",
       "387    0.342879\n",
       "388    0.339081\n",
       "389    0.402750\n",
       "390    0.400936\n",
       "391    0.487194\n",
       "392    0.222029\n",
       "393    0.438725\n",
       "394    0.253423\n",
       "395    0.488670\n",
       "396    0.165504\n",
       "397    0.181062\n",
       "398    0.463667\n",
       "399    0.300731\n",
       "Length: 400, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#data loading \n",
    "data=pd.read_csv(\"./data/admission.csv\", sep=\",\")  #sep=\",\" default값\n",
    "data_x = data[[\"gre\",\"gpa\",\"rank\"]]  #sex는 값들이 문자, pclass는 낮은 숫자가 가중치가 높음 => 바꿔줘야 함\n",
    "data_y = data[\"admit\"]\n",
    "\n",
    "rank_dummies = pd.get_dummies(data_x[\"rank\"],prefix=\"rank\") #특정컬럼에 대해 더미 컬럼을 얻을 수 있음\n",
    "data_x=data_x.join(rank_dummies)\n",
    "data_x.drop(\"rank\", axis=1, inplace=True)   #inplace=True 원본을 지워라, axis=1열방향\n",
    "\n",
    "logit = sm.Logit(data_y,data_x)  #모델생성\n",
    "result=logit.fit() #학습과정\n",
    "result.predict(data_x)  #예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#머신러닝\n",
    "#supervised learning(지도학습)\n",
    "#-training data set에 label이 붙어 있음\n",
    "#1.simple linear regression : 독립변수 한개(입력 파라미터 한개), hypothesis = w*x+b, cost function =>정확도를 알 수 없음\n",
    "#2.mutiple linear regression : 독립변수 여러개(입력 파라미터 두개 이상), hypothesis =  x*w+b  =>정확도를 알 수 없음\n",
    "#3.logistic regression(lable이 0 or 1) : 실제로 현실에서 많이 이용됨, 정확도를 측정할 수 있음(accuracy),다른말로 binary classification, \n",
    "#                                       H= sigmoid(w*x+b)\n",
    "#4.multinomial classification\n",
    "#둘중에 하나를 선택하는 선(ex A/BC  B/AC  C/AB) 여러개의 logistic이 합쳐져 있는 것\n",
    "#어떤 값이 될 확률이 높은가를 나타냄\n",
    "\n",
    "#unsupervised learning(비지도학습)\n",
    "#-training data set에 label이 붙어있지 않음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.609132\n",
      "0.74994564\n",
      "0.61223316\n",
      "0.55954236\n",
      "0.52501345\n",
      "0.4976689\n",
      "0.47433987\n",
      "0.4537032\n",
      "0.4350689\n",
      "0.4180233\n",
      "0.85714287\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Classification\n",
    "import tensorflow as tf\n",
    "#1.data loading\n",
    "#2.training data set\n",
    "x_data = [[10,7,8,5],\n",
    "         [8,8,9,4],\n",
    "         [7,8,2,3],\n",
    "         [6,3,9,3],\n",
    "         [7,5,7,4],\n",
    "         [3,5,6,2],\n",
    "         [2,4,3,1]]\n",
    "y_data = [[1,0,0],                   #[A,B,C]  = A위치가 1이기에 A를 나타냄\n",
    "         [1,0,0],\n",
    "         [0,1,0],                   #[A,B,C]  = B위치가 1이기에 B를 나타냄\n",
    "         [0,1,0],\n",
    "         [0,1,0],\n",
    "         [0,0,1],\n",
    "         [0,0,1],]        \n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,4], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "\n",
    "#weight & bias\n",
    "W =tf.Variable(tf.random_normal([4,3]), name=\"weight\")\n",
    "b =tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "logit = tf.matmul(X,W)+b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "#Cost(Loss) function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))\n",
    "\n",
    "#train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)   #w값을 얼마만큼 줄여나갈것인가\n",
    "\n",
    "#session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) #변수 초기화\n",
    "\n",
    "#학습\n",
    "for step in range(3000):         #데이터가 작으니 많이 돌릴 수 있음'ㅅ'\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data,Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(cost_val)\n",
    "\n",
    "\n",
    "#Accuracy\n",
    "#predict = H\n",
    "#H => [[0.3  0.6  0.1]] 형태로 나타남\n",
    "\n",
    "predict = tf.argmax(H,1)        #가장 큰 값의 인덱스를 알려줌\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(sess.run(accuracy,feed_dict={X:x_data,Y:y_data}) )\n",
    "\n",
    "#예측\n",
    "result=sess.run(predict, feed_dict={X:[[5,3,9,4]]})\n",
    "if result[0] == 0:\n",
    "    print(\"A\")\n",
    "elif result[0] == 1:\n",
    "    print(\"B\")\n",
    "else:\n",
    "    print(\"c\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.283905\n",
      "12.45308\n",
      "41.190025\n",
      "25.17555\n",
      "5.767573\n",
      "7.5159054\n",
      "22.493662\n",
      "23.323841\n",
      "8.134661\n",
      "9.178581\n",
      "0.70015\n",
      "normal\n"
     ]
    }
   ],
   "source": [
    "#bmi 예제 (multinomial classification)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#1.Data loading\n",
    "data = pd.read_csv(\"./data/bmi.csv\", sep=\",\", skiprows=3)\n",
    "data = data.dropna(how=\"any\") # 결측값 제거\n",
    "df_x = data[[\"height\",\"weight\"]]\n",
    "df_y = data[\"label\"]\n",
    "df_y #=> 0,1,2 [1,0,0]  = 0\n",
    "\n",
    "y_data=tf.one_hot(df_y,3)\n",
    "sess=tf.Session()\n",
    "y_data=sess.run(y_data)\n",
    "\n",
    "\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "\n",
    "#weight & bias\n",
    "W =tf.Variable(tf.random_normal([2,3]), name=\"weight\")\n",
    "b =tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "logit = tf.matmul(X,W)+b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "#Cost(Loss) function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))\n",
    "\n",
    "#train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)   #w값을 얼마만큼 줄여나가는 가\n",
    "\n",
    "#session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습\n",
    "for step in range(3000):         #데이터가 작으니 많이 돌릴 수 있음'ㅅ'\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:df_x,Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(cost_val)\n",
    "\n",
    "#Accuracy\n",
    "#predict = H\n",
    "#H => [[0.3  0.6  0.1]] 형태로 나타남\n",
    "\n",
    "predict = tf.argmax(H,1)        #가장 큰 값의 인덱스를 알려줌\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(sess.run(accuracy,feed_dict={X:df_x,Y:y_data}) )\n",
    "\n",
    "#예측\n",
    "result=sess.run(predict, feed_dict={X:[[195,70]]})\n",
    "if result[0] == 0:\n",
    "    print(\"thin\")\n",
    "elif result[0] == 1:\n",
    "    print(\"normal\")\n",
    "else:\n",
    "    print(\"fat\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7766238\n",
      "0.73740894\n",
      "0.6035024\n",
      "0.53363365\n",
      "0.4880373\n",
      "0.45474347\n",
      "0.4287986\n",
      "0.40771258\n",
      "0.39006877\n",
      "0.37498158\n",
      "0.94766665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#bmi 예제 (multinomial classification)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "#warning이 출력되지 않도록\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "#1.Data loading\n",
    "data = pd.read_csv(\"./data/bmi.csv\", sep=\",\", skiprows=3)\n",
    "data = data.dropna(how=\"any\") # 결측값 제거  but 결측값을 제거하는 것보단 대체하는 것이 좋음 \n",
    "\n",
    "num_data=int(data.shape[0]*0.7)\n",
    "data_train=data.loc[:num_data,:]\n",
    "data_test=data.loc[num_data:,:]\n",
    "\n",
    "train_x = data_train[[\"height\",\"weight\"]]\n",
    "train_y = data_train[\"label\"]\n",
    "\n",
    "test_x = data_test[[\"height\",\"weight\"]]\n",
    "test_y = data_test[\"label\"]\n",
    "\n",
    "sess = tf.Session()\n",
    "scaler =MinMaxScaler()\n",
    "\n",
    "\n",
    "#fit_transform(x) : x의 값들에서 최댓값 최솟값을 알아낸 뒤 (최댓값(해당데이터)-최솟값)/(최댓값(전체데이터)-최솟값)을 적용해 \n",
    "#                   모든 값을 0과 1사이로 바꿔줌(정규화) 그리고 그 최댓값과 최솟값을 scaler에 저장\n",
    "#transform(x) : fit_transform과 비슷한데 최댓값과 최솟값을 자기 데이터 내에서 찾아내는게 아니라 이미 앞에서 얻어낸(fit_transform)의 최댓값\n",
    "#               과 최솟값을 사용해서 정규화를 함\n",
    "\n",
    "train_x_data=scaler.fit_transform(train_x.values)  \n",
    "train_y_data=sess.run(tf.one_hot(train_y,3))   #tf.one_hot(df_train_y,3).eval(session=sess)\n",
    "\n",
    "test_x_data=scaler.transform(test_x.values)   #\n",
    "test_y_data=sess.run(tf.one_hot(test_y,3))   #tf.one_hot(df_train_y,3).eval(session=sess)\n",
    "\n",
    "\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "\n",
    "#weight & bias\n",
    "W =tf.Variable(tf.random_normal([2,3]), name=\"weight\")\n",
    "b =tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "logit = tf.matmul(X,W)+b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "#Cost(Loss) function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))\n",
    "\n",
    "#train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)   #w값을 얼마만큼 줄여나가는 가\n",
    "\n",
    "#session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습\n",
    "for step in range(3000):         #데이터가 작으니 많이 돌릴 수 있음'ㅅ'\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:train_x_data,Y:train_y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(cost_val)\n",
    "\n",
    "#Accuracy\n",
    "#predict = H\n",
    "#H => [[0.3  0.6  0.1]] 형태로 나타남\n",
    "\n",
    "predict = tf.argmax(H,1)        #가장 큰 값의 인덱스를 알려줌\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(sess.run(accuracy,feed_dict={X:test_x_data,Y:test_y_data}) )\n",
    "\n",
    "#예측\n",
    "result=sess.run(H, feed_dict={X:scaler.transform([[195,70]])})\n",
    "#데이터를 정규화(0~1사이의 값)시켰기 때문에 예측하기위해 입력하는 데이터타입([195, 70])으로는 측정할 수가 없다. 그래서 넣는 값도 \n",
    "#scaler에 저장된 최댓값과 최솟값으로 정규화시켜서 측정을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-12021d52ffef>:14: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "1.2332479\n",
      "0.59389\n",
      "1.0663563\n",
      "0.41165864\n",
      "0.40290734\n",
      "0.5910589\n",
      "0.6547582\n",
      "0.41876388\n",
      "0.5416397\n",
      "0.42193505\n",
      "0.902\n"
     ]
    }
   ],
   "source": [
    "#MNIST - Multinomial Classification\n",
    "#입력데이터(이미지에 대한 픽셀 데이터)\n",
    "#원래 이미지 데이터는 3차원 데이터인데 흑백이고 2차원 데이터를 1차원으로 변환해서 입력을 받는다\n",
    "#약 5만 5천개의 이미지를 입력으로 받음\n",
    "#입력데이터의(x parameter)의 shape =>(5500, 784)\n",
    "#y측 lable의 shape=(55000, 10)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#1.Data loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)   #one_hot이 설정되어있는 형태로 불러들임 > 데이터 전처리 필요 없음\n",
    "#mnist.train.num_examples   #이미지 몇장 우리에게 제공되는지\n",
    "#mnist.train.images.shape   #x쪽 형태\n",
    "#mnist.train.labels[0]  # 출력결과 array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]) == 7을 의미\n",
    "#sess=tf.Session()\n",
    "#sess.run(tf.argmax(mnist.train.labels[0].reshape(-1,10),1)) # 출력결과 array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]) == 7을 의미\n",
    "#argmax 2차원 배열만 사용가능, 몇번째 순번이 1인지를 알아냄     출력결과 == array([7], dtype=int64)\n",
    "#plt.imshow(mnist.train.images[0].reshape(28,28), cmap=\"Greys\", interpolation=\"nearest\")     #첫번째 그림 > 원래이미지 형태로 바꿈 > plt.imshow 이미지로 보여줌 >greys: 흑백으로 출력\n",
    "\n",
    "\n",
    "#2.Placeholder\n",
    "X=tf.placeholder(shape=[None,784], dtype=tf.float32)   #입력데이터의 shape에 따른다\n",
    "Y=tf.placeholder(shape=[None,10], dtype=tf.float32)    #0-9까지 표현되니깐 10\n",
    "\n",
    "#3.weight & bias \n",
    "W=tf.Variable(tf.random_normal([784,10]), name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([10]), name=\"bias\")    #logistic 10개\n",
    "\n",
    "#4.Hypothesis\n",
    "logit=tf.matmul(X,W)+b\n",
    "H=tf.nn.softmax(logit)\n",
    "\n",
    "#5.Cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))\n",
    "#크로스 엔트로피 함수와 소프트맥스 함수 함께 구현\n",
    "#크로스 엔트로피는 추정된 클래스의 확률이 타깃 클래스에 얼마나 잘 맞는지 측정하는 용도로 종종 사용\n",
    "#logits = softmax 함수를 적용해서 정규화하기전의 모델의 출력값\n",
    "#labels=정답레이블\n",
    "\n",
    "#6.train\n",
    "train=tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "#7.session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) \n",
    "\n",
    "#8.학습   => 이전의 for문 방법은 데이터가 작기때문에 가능했다, but 데이터가 커지면 대치처리를 해줘야 함\n",
    "train_epoch = 30   #우리가 가지고 있는 데이터를 가지고 n번 학습하는 것 = n epoch\n",
    "batch_size = 100   #한번에 읽어들일 데이터의 크기, 몇개씩 잘라서 들고올건가\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)  #반복횟수 : 전체데이터 / batch_size \n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)       #전체의 훈련데이터(mnist.train)에서 데이터를 100개씩 가져옴\n",
    "        _, cost_val= sess.run([train, cost],feed_dict={X:batch_x,Y:batch_y})\n",
    "        \n",
    "    if step % 3 == 0:\n",
    "        print(cost_val)\n",
    "        \n",
    "#accuracy\n",
    "predict=tf.argmax(H,1)\n",
    "correct=tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "#정확도 출력\n",
    "print(sess.run(accuracy, feed_dict={X:mnist.test.images,Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
