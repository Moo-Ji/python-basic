{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "# tensorflow\n",
    "# google 만든 머신러닝을 위한 library( python, c )\n",
    "# tensorflow를 이용해 보아요!\n",
    "# Hello World를 출력해 보아요!\n",
    "import tensorflow as tf\n",
    "\n",
    "# tensorflow의 구성요소(3가지)\n",
    "# 1. node : 수학적인 연산을 담당, 데이터의 입출력\n",
    "# 2. Tensor : 다차원 array(matrix)\n",
    "# 3. edge : 한 node가 가지고 있는 tensor를 다른 node로 이동\n",
    "\n",
    "my_node = tf.constant(\"Hello World\")\n",
    "\n",
    "sess = tf.Session()  # session, runner(node를 실행시키는 놈)\n",
    "\n",
    "print(sess.run(my_node).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0, 20.0, 30.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "node1 = tf.constant(10, dtype=tf.float32)\n",
    "node2 = tf.constant(20, dtype=tf.float32)\n",
    "\n",
    "node3 = node1 + node2 # tf.add(node1,node2)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run([node1,node2,node3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 13., 15.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# placeholder ( 데이터를 받아들이는 그릇 )\n",
    "import tensorflow as tf\n",
    "\n",
    "node1 = tf.placeholder(dtype=tf.float32)\n",
    "node2 = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "node3 = node1 + node2\n",
    "\n",
    "sess = tf.Session()\n",
    "# sess.run(node3, feed_dict={node1:input(), node2:input()})\n",
    "sess.run(node3, feed_dict={node1:[1,2,3], node2:[10,11,12]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_14:0' shape=(3,) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# node1 = tf.constant(3, dtype=tf.float32)\n",
    "# node1\n",
    "node1 = tf.constant([1,2,3], dtype=tf.float32)\n",
    "node1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:[0.50095165],b:[-1.6746306],cost:42.499759674072266\n",
      "w:[2.360798],b:[0.17982095],cost:0.09696769714355469\n",
      "w:[2.17526],b:[0.60159266],cost:0.022880464792251587\n",
      "w:[2.0851336],b:[0.8064714],cost:0.005398837383836508\n",
      "w:[2.041355],b:[0.9059917],cost:0.0012739243684336543\n",
      "w:[2.020088],b:[0.95433503],cost:0.0003005896869581193\n",
      "w:[2.0097578],b:[0.9778179],cost:7.092850137269124e-05\n",
      "w:[2.0047405],b:[0.9892244],cost:1.6738096746848896e-05\n",
      "w:[2.0023036],b:[0.994764],cost:3.9526903492514975e-06\n",
      "w:[2.0011203],b:[0.9974542],cost:9.343953024654184e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.004223], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 간단한 linear regression을 이용한 machine learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# training data set\n",
    "x_data = [1,2,3]  # 독립변수, 입력데이터\n",
    "y_data = [3,5,7]  # 종속변수, 입력데이터의 label\n",
    "\n",
    "# placeholder\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "y = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Weight & bias 정의\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis ( 우리가 최종적으로 알아내야 하는 직선 )\n",
    "#              데이터에 가장 인접한 직선\n",
    "#              예측모델이 만들어졌으니 prediction이 가능\n",
    "H = W * x + b\n",
    "\n",
    "# Cost function(Loss function, 비용함수)\n",
    "# Cost function이 최소가 되는 W와 b값을 구하는 것이 목적\n",
    "cost = tf.reduce_mean(tf.square(H - y))\n",
    "\n",
    "# cost function의 minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# 그래프를 실행시키기 위한 session\n",
    "sess = tf.Session()\n",
    "# Variable을 사용할 경우 초기화를 시켜줘야 해요!!\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3000):\n",
    "    _, w_val, b_val, cost_val = sess.run([train,W,b,cost],\n",
    "                                        feed_dict={x:x_data, y:y_data})\n",
    "    if step % 300 == 0: # 300번 반복될때마다 출력\n",
    "        print(\"w:{},b:{},cost:{}\".format(w_val,b_val,cost_val))\n",
    "\n",
    "##### Prediction\n",
    "sess.run(H, feed_dict={x:10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 516.58544921875\n",
      "cost : 4.522102355957031\n",
      "cost : 4.343588352203369\n",
      "cost : 4.2141194343566895\n",
      "cost : 4.1202263832092285\n",
      "cost : 4.052131175994873\n",
      "cost : 4.002747535705566\n",
      "cost : 3.966930389404297\n",
      "cost : 3.9409542083740234\n",
      "cost : 3.922116756439209\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([32.529766], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "### 기본적인 linear regression 예제\n",
    "import tensorflow as tf # tensorflow module 불러들여요\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "np.random.seed(12345)\n",
    "# training data set \n",
    "x_data = np.arange(0,20,1)\n",
    "y_data = np.array([ t*2 + np.random.normal(2,2) for t in x_data ])\n",
    "# 일단 눈으로 먼저 확인을 해 보아요!!\n",
    "plt.scatter(x_data,y_data)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(dtype=tf.float32)\n",
    "Y = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = W * X + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(H-Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data,Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "# 입력데이터에 대한 처리가 이루어져야 정상적으로 학습이 진행\n",
    "# 될 수 있어요!! ( 조금 이따가 얘기해요 !! )\n",
    "# 만약 학습이 정상적으로 이루어졌으면 W,b값이 결정되게 되요!\n",
    "x_line = np.arange(0,20,1)\n",
    "y_line = np.array([ sess.run(W) * t + sess.run(b) for t in x_line])\n",
    "# print(y_line)\n",
    "plt.plot(x_line,y_line,\"r\")\n",
    "plt.show()\n",
    "# Prediction\n",
    "sess.run(H, feed_dict={X:15})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0   41.0    190.0   7.4    67      5    1\n",
       "1   36.0    118.0   8.0    72      5    2\n",
       "2   12.0    149.0  12.6    74      5    3\n",
       "3   18.0    313.0  11.5    62      5    4\n",
       "6   23.0    299.0   8.6    65      5    7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.55963303, 0.27717391, 0.25      ],\n",
       "       [0.33944954, 0.30978261, 0.375     ],\n",
       "       [0.43425076, 0.55978261, 0.425     ],\n",
       "       [0.93577982, 0.5       , 0.125     ],\n",
       "       [0.89296636, 0.3423913 , 0.2       ],\n",
       "       [0.28134557, 0.625     , 0.05      ],\n",
       "       [0.03669725, 0.9673913 , 0.1       ],\n",
       "       [0.76146789, 0.40217391, 0.3       ],\n",
       "       [0.86544343, 0.375     , 0.225     ],\n",
       "       [0.81651376, 0.4673913 , 0.275     ],\n",
       "       [0.17737003, 0.5923913 , 0.025     ],\n",
       "       [1.        , 0.5       , 0.175     ],\n",
       "       [0.91743119, 0.52717391, 0.225     ],\n",
       "       [0.21712538, 0.875     , 0.        ],\n",
       "       [0.96330275, 0.5       , 0.275     ],\n",
       "       [0.11314985, 0.40217391, 0.125     ],\n",
       "       [0.0030581 , 0.40217391, 0.05      ],\n",
       "       [0.95718654, 0.77717391, 0.4       ],\n",
       "       [0.05504587, 0.40217391, 0.1       ],\n",
       "       [0.25993884, 0.52717391, 0.1       ],\n",
       "       [0.01834862, 0.52717391, 0.25      ],\n",
       "       [0.74923547, 0.68478261, 0.6       ],\n",
       "       [0.66055046, 0.18478261, 0.55      ],\n",
       "       [0.83180428, 0.27717391, 0.475     ],\n",
       "       [0.36697248, 0.40217391, 0.625     ],\n",
       "       [0.86850153, 0.625     , 0.825     ],\n",
       "       [0.96636086, 0.5       , 0.75      ],\n",
       "       [0.43119266, 0.30978261, 0.625     ],\n",
       "       [0.56269113, 0.68478261, 0.5       ],\n",
       "       [0.8470948 , 1.        , 0.375     ],\n",
       "       [0.09174312, 0.375     , 0.2       ],\n",
       "       [0.34556575, 0.5       , 0.4       ],\n",
       "       [0.39755352, 0.43478261, 0.475     ],\n",
       "       [0.80122324, 0.09782609, 0.675     ],\n",
       "       [0.73700306, 0.375     , 0.7       ],\n",
       "       [0.70030581, 0.375     , 0.6       ],\n",
       "       [0.51376147, 0.125     , 0.65      ],\n",
       "       [0.93883792, 0.4673913 , 0.65      ],\n",
       "       [0.82262997, 0.15217391, 0.775     ],\n",
       "       [0.79510703, 0.2173913 , 0.875     ],\n",
       "       [0.81039755, 0.18478261, 0.875     ],\n",
       "       [0.51376147, 0.27717391, 0.8       ],\n",
       "       [0.78593272, 0.65217391, 0.4       ],\n",
       "       [0.51376147, 0.68478261, 0.6       ],\n",
       "       [0.12538226, 0.65217391, 0.575     ],\n",
       "       [0.77370031, 0.25      , 0.6       ],\n",
       "       [0.81651376, 0.43478261, 0.625     ],\n",
       "       [0.85015291, 0.2173913 , 0.675     ],\n",
       "       [0.55045872, 0.15217391, 0.75      ],\n",
       "       [0.65137615, 0.5       , 0.7       ],\n",
       "       [0.        , 0.25      , 0.425     ],\n",
       "       [0.87767584, 0.3423913 , 0.725     ],\n",
       "       [0.66055046, 0.30978261, 0.7       ],\n",
       "       [0.22629969, 0.3423913 , 0.625     ],\n",
       "       [0.2293578 , 0.52717391, 0.725     ],\n",
       "       [0.62996942, 0.27717391, 0.775     ],\n",
       "       [0.81957187, 0.27717391, 0.725     ],\n",
       "       [0.75229358, 0.27717391, 0.65      ],\n",
       "       [0.75535168, 0.375     , 0.6       ],\n",
       "       [0.2324159 , 0.25      , 0.6       ],\n",
       "       [0.05198777, 0.625     , 0.6       ],\n",
       "       [0.21406728, 0.27717391, 0.625     ],\n",
       "       [0.75840979, 0.0923913 , 0.8       ],\n",
       "       [0.67889908, 0.43478261, 0.825     ],\n",
       "       [0.6116208 , 0.30978261, 0.825     ],\n",
       "       [0.56574924, 0.5       , 0.725     ],\n",
       "       [0.81345566, 0.5       , 0.625     ],\n",
       "       [0.4587156 , 0.40217391, 0.575     ],\n",
       "       [0.19571865, 0.43478261, 0.5       ],\n",
       "       [0.13455657, 0.2173913 , 0.55      ],\n",
       "       [0.33027523, 0.27717391, 0.475     ],\n",
       "       [0.72477064, 0.4673913 , 0.525     ],\n",
       "       [0.55963303, 0.43478261, 0.525     ],\n",
       "       [0.7706422 , 0.7173913 , 0.5       ],\n",
       "       [0.08868502, 0.65217391, 0.375     ],\n",
       "       [0.62691131, 0.40217391, 0.55      ],\n",
       "       [0.70642202, 0.05978261, 0.6       ],\n",
       "       [0.63608563, 0.30978261, 0.725     ],\n",
       "       [0.59938838, 0.40217391, 1.        ],\n",
       "       [0.66666667, 0.        , 0.925     ],\n",
       "       [0.70336391, 0.2173913 , 0.975     ],\n",
       "       [0.55351682, 0.2173913 , 0.925     ],\n",
       "       [0.48929664, 0.25      , 0.85      ],\n",
       "       [0.58103976, 0.15217391, 0.875     ],\n",
       "       [0.5382263 , 0.02717391, 0.9       ],\n",
       "       [0.55657492, 0.125     , 0.9       ],\n",
       "       [0.26911315, 0.27717391, 0.75      ],\n",
       "       [0.25993884, 0.7173913 , 0.675     ],\n",
       "       [0.74923547, 0.4673913 , 0.575     ],\n",
       "       [0.65137615, 0.43478261, 0.525     ],\n",
       "       [0.68195719, 0.4673913 , 0.45      ],\n",
       "       [0.7706422 , 0.40217391, 0.4       ],\n",
       "       [0.70030581, 0.68478261, 0.6       ],\n",
       "       [0.7706422 , 0.7173913 , 0.475     ],\n",
       "       [0.70642202, 0.2173913 , 0.5       ],\n",
       "       [0.05198777, 0.4673913 , 0.35      ],\n",
       "       [0.32110092, 0.5       , 0.35      ],\n",
       "       [0.70336391, 0.25      , 0.525     ],\n",
       "       [0.66360856, 0.625     , 0.25      ],\n",
       "       [0.06116208, 0.43478261, 0.475     ],\n",
       "       [0.70642202, 0.43478261, 0.275     ],\n",
       "       [0.59327217, 0.30978261, 0.625     ],\n",
       "       [0.70642202, 0.55978261, 0.175     ],\n",
       "       [0.02140673, 0.375     , 0.35      ],\n",
       "       [0.40366972, 0.43478261, 0.6       ],\n",
       "       [0.12844037, 0.43478261, 0.3       ],\n",
       "       [0.03975535, 0.77717391, 0.15      ],\n",
       "       [0.56880734, 0.25      , 0.325     ],\n",
       "       [0.56269113, 0.65217391, 0.45      ],\n",
       "       [0.37920489, 0.30978261, 0.475     ],\n",
       "       [0.66055046, 0.5       , 0.275     ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ozone데이터를 이용한 multiple linear regression\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## 1. Data Loading\n",
    "data = pd.read_csv(\"./data/ozone/ozone.csv\", sep=\",\")\n",
    "df = data.dropna(how=\"any\", inplace=False) # 111개의 행\n",
    "display(df.head())\n",
    "# 2. training data set\n",
    "x_data = MinMaxScaler().fit_transform(\n",
    "            df[[\"Solar.R\",\"Wind\",\"Temp\"]].values)\n",
    "y_data = MinMaxScaler().fit_transform(\n",
    "        df[\"Ozone\"].values.reshape(-1,1))\n",
    "x_data\n",
    "# 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>34.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>45.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>115.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>37.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>29.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>71.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>39.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>23.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>21.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>37.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>85.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>96.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>91</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>78.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>92</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>73.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>93</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>91.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>93</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>47.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>32.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>20.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>23.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>21.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>24.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>73</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>44.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>21.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>28.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>13.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>46.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>18.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>24.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>16.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>13.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>36.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>30.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>70</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>14.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>18.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>20.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0     41.0    190.0   7.4    67      5    1\n",
       "1     36.0    118.0   8.0    72      5    2\n",
       "2     12.0    149.0  12.6    74      5    3\n",
       "3     18.0    313.0  11.5    62      5    4\n",
       "6     23.0    299.0   8.6    65      5    7\n",
       "7     19.0     99.0  13.8    59      5    8\n",
       "8      8.0     19.0  20.1    61      5    9\n",
       "11    16.0    256.0   9.7    69      5   12\n",
       "12    11.0    290.0   9.2    66      5   13\n",
       "13    14.0    274.0  10.9    68      5   14\n",
       "14    18.0     65.0  13.2    58      5   15\n",
       "15    14.0    334.0  11.5    64      5   16\n",
       "16    34.0    307.0  12.0    66      5   17\n",
       "17     6.0     78.0  18.4    57      5   18\n",
       "18    30.0    322.0  11.5    68      5   19\n",
       "19    11.0     44.0   9.7    62      5   20\n",
       "20     1.0      8.0   9.7    59      5   21\n",
       "21    11.0    320.0  16.6    73      5   22\n",
       "22     4.0     25.0   9.7    61      5   23\n",
       "23    32.0     92.0  12.0    61      5   24\n",
       "27    23.0     13.0  12.0    67      5   28\n",
       "28    45.0    252.0  14.9    81      5   29\n",
       "29   115.0    223.0   5.7    79      5   30\n",
       "30    37.0    279.0   7.4    76      5   31\n",
       "37    29.0    127.0   9.7    82      6    7\n",
       "39    71.0    291.0  13.8    90      6    9\n",
       "40    39.0    323.0  11.5    87      6   10\n",
       "43    23.0    148.0   8.0    82      6   13\n",
       "46    21.0    191.0  14.9    77      6   16\n",
       "47    37.0    284.0  20.7    72      6   17\n",
       "..     ...      ...   ...   ...    ...  ...\n",
       "122   85.0    188.0   6.3    94      8   31\n",
       "123   96.0    167.0   6.9    91      9    1\n",
       "124   78.0    197.0   5.1    92      9    2\n",
       "125   73.0    183.0   2.8    93      9    3\n",
       "126   91.0    189.0   4.6    93      9    4\n",
       "127   47.0     95.0   7.4    87      9    5\n",
       "128   32.0     92.0  15.5    84      9    6\n",
       "129   20.0    252.0  10.9    80      9    7\n",
       "130   23.0    220.0  10.3    78      9    8\n",
       "131   21.0    230.0  10.9    75      9    9\n",
       "132   24.0    259.0   9.7    73      9   10\n",
       "133   44.0    236.0  14.9    81      9   11\n",
       "134   21.0    259.0  15.5    76      9   12\n",
       "135   28.0    238.0   6.3    77      9   13\n",
       "136    9.0     24.0  10.9    71      9   14\n",
       "137   13.0    112.0  11.5    71      9   15\n",
       "138   46.0    237.0   6.9    78      9   16\n",
       "139   18.0    224.0  13.8    67      9   17\n",
       "140   13.0     27.0  10.3    76      9   18\n",
       "141   24.0    238.0  10.3    68      9   19\n",
       "142   16.0    201.0   8.0    82      9   20\n",
       "143   13.0    238.0  12.6    64      9   21\n",
       "144   23.0     14.0   9.2    71      9   22\n",
       "145   36.0    139.0  10.3    81      9   23\n",
       "146    7.0     49.0  10.3    69      9   24\n",
       "147   14.0     20.0  16.6    63      9   25\n",
       "148   30.0    193.0   6.9    70      9   26\n",
       "150   14.0    191.0  14.3    75      9   28\n",
       "151   18.0    131.0   8.0    76      9   29\n",
       "152   20.0    223.0  11.5    68      9   30\n",
       "\n",
       "[111 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Data Loading\n",
    "data = pd.read_csv(\"./data/ozone/ozone.csv\", sep=\",\")\n",
    "df = data.dropna(how=\"any\", inplace=False)\n",
    "display(df)\n",
    "# 독립변수와 종속변수를 뽑아요\n",
    "x = df[\"Temp\"]\n",
    "y = df[\"Ozone\"]\n",
    "\n",
    "result = stats.linregress(x,y)\n",
    "w = result[0]\n",
    "b = result[1]\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,w*x+b,\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple linear regression\n",
    "import tensorflow as tf\n",
    "\n",
    "# training data set\n",
    "x_data = [[73,80,75],\n",
    "          [93,88,93],\n",
    "          [89,91,90],\n",
    "          [96,98,100],\n",
    "          [73,66,70]]\n",
    "\n",
    "y_data = [[152],\n",
    "          [185],\n",
    "          [180],\n",
    "          [196],\n",
    "          [142]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,3],dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1],dtype=tf.float32)\n",
    "\n",
    "# weight & bias\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "# H = W * x + b\n",
    "H = tf.matmul(X,W) + b\n",
    "\n",
    "# 그 다음부터는 동일과정 진행\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost : 0.2827492952346802\n",
      "Cost : 0.04800090938806534\n",
      "Cost : 0.0436614528298378\n",
      "Cost : 0.04354085773229599\n",
      "Cost : 0.043537504971027374\n",
      "Cost : 0.04353741556406021\n",
      "Cost : 0.04353741183876991\n",
      "Cost : 0.04353741928935051\n",
      "Cost : 0.04353741928935051\n",
      "Cost : 0.04353741928935051\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([5.973681], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Simple Linear Regression\n",
    "import tensorflow as tf\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# training data set\n",
    "x_data = [1,2,5,8,10]\n",
    "y_data = [0,0,0,1,1]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(dtype=tf.float32)\n",
    "Y = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = W * X + b\n",
    "\n",
    "# Cost(Loss) function - 최소제곱법\n",
    "# Cost 함수의 값이 최소가 되는 W,b를 찾는게 목적\n",
    "cost = tf.reduce_mean(tf.square(H-Y))\n",
    "\n",
    "# train node를 생성\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost], \n",
    "                           feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val))\n",
    "\n",
    "plt.scatter(x_data,y_data)\n",
    "plt.plot(x_data, sess.run(W)*x_data + sess.run(b),\"r\")\n",
    "plt.show()\n",
    "x = (0.5 - sess.run(b)) / sess.run(W) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn   # Sample Data를 가져오기 위한 utility module\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings  # warning제어를 목적으로 사용\n",
    "\n",
    "# warning을 표시하지 않아요\n",
    "warnings.filterwarnings(action=\"ignore\") \n",
    "\n",
    "# x : x parameter( 2개 )\n",
    "# y : label ( 0 or 1 )\n",
    "x,y = mglearn.datasets.make_forge()\n",
    "# print(x)\n",
    "\n",
    "mglearn.discrete_scatter(x[:,0], x[:,1], y)\n",
    "model = LogisticRegression()\n",
    "clf = model.fit(x,y)\n",
    "\n",
    "mglearn.plots.plot_2d_separator(clf,x,fill=False, eps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 1.6460025310516357\n",
      "cost : 0.5601195693016052\n",
      "cost : 0.49234142899513245\n",
      "cost : 0.4417272210121155\n",
      "cost : 0.40330055356025696\n",
      "cost : 0.3735801577568054\n",
      "cost : 0.35011354088783264\n",
      "cost : 0.33119654655456543\n",
      "cost : 0.3156454265117645\n",
      "cost : 0.30263060331344604\n",
      "정확도 : 0.8571428656578064\n",
      "예측값 : [[0.]]\n"
     ]
    }
   ],
   "source": [
    "### Tensorflow를 이용한 Logistic Regression\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data Loading\n",
    "# 파일이나 network를 통해서 데이터를 로딩한 후 전처리 과정\n",
    "\n",
    "# training data set ( 2차원 matrix )\n",
    "x_data = [[10,0],\n",
    "          [8,1],\n",
    "          [3,3],\n",
    "          [2,3],\n",
    "          [5,1],\n",
    "          [2,0],\n",
    "          [1,0]]\n",
    "y_data = [[1],[1],[1],[1],[0],[0],[0]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# Cost function\n",
    "# cost = -tf.reduce_mean( y * tf.log(H) + (1-Y) * tf.log(1-H))\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                            labels=Y))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data,\n",
    "                                                   Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "# 우리가 만든 모델이 얼마나 정확한지를 측정\n",
    "# accuracy\n",
    "predict = tf.cast( H > 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy,\n",
    "                                 feed_dict={X:x_data, Y:y_data})))\n",
    "\n",
    "# prediction\n",
    "print(\"예측값 : {}\".format(sess.run(predict, \n",
    "                                 feed_dict={X:[[3,1]]})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Logistic Regression ( Binary Classification )\n",
    "### 정리!!\n",
    "\n",
    "## download : http://tagme.to/moon9342/logistic\n",
    "## 실습예제 1. - Titanic\n",
    "## 실습예제 2. - Admission\n",
    "##               주어진 데이터의 70%를 training용으로 사용\n",
    "##               나머지 30%를 test용으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost : 0.7142138481140137\n",
      "Cost : 0.496805340051651\n",
      "Cost : 0.47965821623802185\n",
      "Cost : 0.4734089970588684\n",
      "Cost : 0.4704672694206238\n",
      "Cost : 0.46870672702789307\n",
      "Cost : 0.46742314100265503\n",
      "Cost : 0.4663620591163635\n",
      "Cost : 0.46542492508888245\n",
      "Cost : 0.46457090973854065\n",
      "정확도 : 0.7833894491195679\n"
     ]
    }
   ],
   "source": [
    "### Titanic 분석 ( Tensorflow )\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## 1. Data Loading\n",
    "data = pd.read_csv(\"./data/titanic/titanic_data.csv\", sep=\",\")\n",
    "data_x = data[[\"Sex\",\"Age\",\"Pclass\",\"Fare\"]]\n",
    "data_y = data[\"Survived\"]\n",
    "Pclass_dummies = pd.get_dummies(data_x[\"Pclass\"], \n",
    "                                prefix=\"Pclass\")\n",
    "data_x = data_x.join(Pclass_dummies)\n",
    "data_x.drop(\"Pclass\", axis=1, inplace=True)\n",
    "Sex_dummies = pd.get_dummies(data_x[\"Sex\"], prefix=\"Sex\")\n",
    "data_x = data_x.join(Sex_dummies)\n",
    "data_x.drop(\"Sex\", axis=1, inplace=True)\n",
    "\n",
    "# training data set\n",
    "x_data = MinMaxScaler().fit_transform(data_x.values)\n",
    "y_data = data_y.values.reshape(-1,1)\n",
    "# x_data.shape ( 891,7 )\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,7], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([7,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                            labels=Y))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(10000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data,\n",
    "                                                   Y:y_data})\n",
    "    if step % 1000 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val))\n",
    "\n",
    "# accuracy 측정\n",
    "predict = tf.cast( H > 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, feed_dict={X:x_data, \n",
    "                                                     Y:y_data})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost : 0.7911784648895264\n",
      "Cost : 0.5480604767799377\n",
      "Cost : 0.5478910207748413\n",
      "Cost : 0.5478899478912354\n",
      "Cost : 0.5478899478912354\n",
      "Cost : 0.5478899478912354\n",
      "Cost : 0.5478899478912354\n",
      "Cost : 0.5478899478912354\n",
      "Cost : 0.5478899478912354\n",
      "Cost : 0.5478899478912354\n",
      "정확도 : 0.6833333373069763\n"
     ]
    }
   ],
   "source": [
    "### Machine Learning - Admission ( TensorFlow )\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## 1. Data Loading\n",
    "data = pd.read_csv(\"./data/admission/admission.csv\", sep=\",\")\n",
    "\n",
    "data_x = data.drop(\"admit\",axis=1)\n",
    "data_y = data[\"admit\"]\n",
    "rank_dummies = pd.get_dummies(data_x[\"rank\"], \n",
    "                                prefix=\"rank\")\n",
    "data_x = data_x.join(rank_dummies)\n",
    "data_x.drop(\"rank\", axis=1, inplace=True)\n",
    "\n",
    "total_data_x = MinMaxScaler().fit_transform(data_x.values)\n",
    "total_data_y = data_y.values.reshape(-1,1)\n",
    "count = int(total_data_x.shape[0] * 0.7)\n",
    "\n",
    "# training data set\n",
    "training_x_data = total_data_x[:count,:]\n",
    "training_y_data = total_data_y[:count,:]\n",
    "# testing data set\n",
    "testing_x_data = total_data_x[count:,:]\n",
    "testing_y_data = total_data_y[count:,:]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,6], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([6,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                            labels=Y))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(50000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:training_x_data,\n",
    "                                                   Y:training_y_data})\n",
    "    if step % 5000 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val))\n",
    "\n",
    "# accuracy 측정\n",
    "predict = tf.cast( H > 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, feed_dict={X:testing_x_data, \n",
    "                                                     Y:testing_y_data})))\n",
    "# print(\"정확도 : {}\".format(sess.run(accuracy, feed_dict={X:training_x_data, \n",
    "#                                                       Y:training_y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n",
      "0.6122448979591837\n"
     ]
    }
   ],
   "source": [
    "### statsmodel.api\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm # conda install statsmodels\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "## 1. Data Loading\n",
    "data = pd.read_csv(\"./data/admission/admission.csv\", sep=\",\")\n",
    "data_x = data.drop(\"admit\",axis=1)\n",
    "data_y = data[\"admit\"]\n",
    "rank_dummies = pd.get_dummies(data_x[\"rank\"], \n",
    "                                prefix=\"rank\")\n",
    "data_x = data_x.join(rank_dummies)\n",
    "data_x.drop(\"rank\", axis=1, inplace=True)\n",
    "logit = sm.Logit(data_y,data_x) # 모델생성\n",
    "result = logit.fit()  # 학습과정\n",
    "result.predict(data_x) # 예측\n",
    "# mask = result.predict(data_x) > 0.5\n",
    "# data_y[mask].shape # 49\n",
    "# data_y[mask].sum() # 30\n",
    "# print(\"{}\".format(30/49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Machine Learning\n",
    "## - Supervised Learning   ( 지도학습 )\n",
    "##   - training data set에 label이 붙어 있어요!!\n",
    "##   => 1. Simple Linear Regression\n",
    "##      독립변수(입력 parameter)가 1개인것을 지칭\n",
    "##       Hypothesis => H = W * x + b, Cost fucntion\n",
    "##   => 2. Multiple Linear Regression \n",
    "##      독립변수(입력 parameter)가 2개이상인것을 지칭\n",
    "##      Hypothesis => H = XW + b\n",
    "##   => 3. Logistic Regression ( lable이 0 or 1 )\n",
    "##      실제로 현실에서 많이 이용되고 있는 학습모델\n",
    "##      정확도를 측정가능.\n",
    "##      다른말로 binary classification\n",
    "##      Hypothesis => sigmoid(XW + b)\n",
    "##     \n",
    "## - UnSupervised Learning ( 비지도학습 )\n",
    "##   - training data set에 label이 붙어 있지 않은경우!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 3.5164682865142822\n",
      "cost : 0.7861059308052063\n",
      "cost : 0.7078590393066406\n",
      "cost : 0.658867359161377\n",
      "cost : 0.6201901435852051\n",
      "cost : 0.5873222351074219\n",
      "cost : 0.5583909749984741\n",
      "cost : 0.5323972105979919\n",
      "cost : 0.5087361931800842\n",
      "cost : 0.48700910806655884\n",
      "정확도 : 0.8571428656578064\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "## Multinomial Classification\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. data loading\n",
    "\n",
    "# 2. training data set\n",
    "x_data = [[10,7,8,5],\n",
    "          [8,8,9,4],\n",
    "          [7,8,2,3],\n",
    "          [6,3,9,3],\n",
    "          [7,5,7,4],\n",
    "          [3,5,6,2],\n",
    "          [2,4,3,1]\n",
    "         ]\n",
    "y_data = [[1,0,0], \n",
    "          [1,0,0],\n",
    "          [0,1,0],\n",
    "          [0,1,0],\n",
    "          [0,1,0],\n",
    "          [0,0,1],\n",
    "          [0,0,1],\n",
    "         ]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,4], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([4,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# Cost(Loss) function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=Y))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data,\n",
    "                                                   Y:y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "# Accuracy\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, feed_dict={X:x_data,\n",
    "                                                     Y:y_data})))\n",
    "# 예측\n",
    "result = sess.run(predict, feed_dict={X:[[5,8,3,4]]})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 2.6160988807678223\n",
      "cost : 0.6999130845069885\n",
      "cost : 0.5821584463119507\n",
      "cost : 0.5189303159713745\n",
      "cost : 0.4770132303237915\n",
      "cost : 0.4460597336292267\n",
      "cost : 0.4217183291912079\n",
      "cost : 0.40179136395454407\n",
      "cost : 0.3850152790546417\n",
      "cost : 0.37059810757637024\n",
      "정확도 : 0.9495000243186951\n",
      "예측값 : [[0.16072062 0.68438685 0.15489258]]\n"
     ]
    }
   ],
   "source": [
    "### BMI 예제 ( multinomial classification )\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "# warning을 출력하지 않도록 지정\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# 1. Data Loading\n",
    "data = pd.read_csv(\"./data/bmi/bmi.csv\", sep=\",\", skiprows=3)\n",
    "# 결치값 제거\n",
    "data = data.dropna(how=\"any\")\n",
    "# training data, testing data\n",
    "num_of_data = int(data.shape[0]*0.7)\n",
    "\n",
    "data_train = data.loc[:num_of_data,:]\n",
    "data_test = data.loc[num_of_data:,:]\n",
    "\n",
    "df_train_x = data_train[[\"height\",\"weight\"]]\n",
    "df_train_y = data_train[\"label\"]\n",
    "df_test_x = data_test[[\"height\",\"weight\"]]\n",
    "df_test_y = data_test[\"label\"]\n",
    "\n",
    "sess = tf.Session()\n",
    "# 2. training data set\n",
    "scaler = MinMaxScaler()\n",
    "train_x_data = scaler.fit_transform(df_train_x.values)\n",
    "# train_y_data = tf.one_hot(df_train_y,3).eval(session=sess)\n",
    "train_y_data = sess.run(tf.one_hot(df_train_y,3))\n",
    "# testing data set\n",
    "test_x_data = scaler.transform(df_test_x.values)\n",
    "test_y_data = tf.one_hot(df_test_y,3).eval(session=sess)\n",
    "\n",
    "# 3. Placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# 4. Weight & bias\n",
    "W = tf.Variable(tf.random_normal([2,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# 5. Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# 6. cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))\n",
    "\n",
    "# 7. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 8. 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 9. 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:train_x_data,\n",
    "                                                   Y:train_y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "        \n",
    "# accuracy\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, feed_dict={X:test_x_data,\n",
    "                                                      Y:test_y_data})))\n",
    "# prediction\n",
    "print(\"예측값 : {}\".format(sess.run(H, \n",
    "                                 feed_dict={X:scaler.transform([[188,75]])})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Cost : 0.8217409253120422\n",
      "Cost : 0.736920952796936\n",
      "Cost : 0.5433945655822754\n",
      "Cost : 0.22439277172088623\n",
      "Cost : 0.2708527743816376\n",
      "Cost : 0.14699268341064453\n",
      "Cost : 0.24060222506523132\n",
      "Cost : 0.19769227504730225\n",
      "Cost : 0.3195491433143616\n",
      "Cost : 0.20795661211013794\n",
      "정확도 : 0.9126999974250793\n"
     ]
    }
   ],
   "source": [
    "##### MNIST - Multinomial Classification\n",
    "##### 입력데이터 - 이미지에 대한 pixel data가 들어와요!\\\n",
    "##### 원래 이미지 데이터는 3차원 데이터인데 흑백이고\n",
    "##### 2차원 데이터를 1차원으로 변환해서 입력을 받아요!\n",
    "##### 약 5만5천개의 이미지를 입력으로 받아요!\n",
    "##### 입력데이터(x parameter)의 shape => ( 55000, 784)\n",
    "##### y측 label의 shape => ( 55000, 10)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# 2. Placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# 3. Wegiht & bias\n",
    "W = tf.Variable(tf.random_normal([784,10]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([10]), name=\"bias\")\n",
    "\n",
    "# 4. Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# 5. Cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=Y))\n",
    "# 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(cost)\n",
    "\n",
    "# 7. Session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8. 학습\n",
    "train_epoch = 30\n",
    "batch_size = 100 # 한번에 읽어들일 데이터의 크기\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost],feed_dict={X:batch_x,\n",
    "                                                      Y:batch_y})\n",
    "    if step % 3 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val)) \n",
    "        \n",
    "# accuracy\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "# 정확도 출력\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy,feed_dict={X:mnist.test.images,\n",
    "                                                    Y:mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
